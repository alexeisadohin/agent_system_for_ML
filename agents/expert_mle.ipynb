{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "  project_name=\"default\",\n",
    "  endpoint=\"http://127.0.0.1:6006/v1/traces\"\n",
    ")\n",
    "\n",
    "#python -m phoenix.server.main serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from smolagents import CodeAgent\n",
    "from smolagents import OpenAIServerModel\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "\n",
    "register()\n",
    "SmolagentsInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt_from_file(filepath):\n",
    "    \"\"\"Загружает текст промпта из указанного файла.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ОШИБКА: Файл промпта не найден: {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ОШИБКА: Не удалось прочитать файл промпта {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIServerModel(\n",
    "    model_id=\"gpt-4.1-mini\",\n",
    "    api_base=\"https://api.openai.com/v1/\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_specialist_agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    additional_authorized_imports=['numpy', 'pandas', 'sklearn', 'catboost'], \n",
    "    name=\"ml_specialist_agent\",\n",
    "    description=\"Specializes in training models, making predictions, and evaluating performance using ROC-AUC metric from sklearn.metrics. Cannot use numpy.random, might use internal model seeds if possible.\"\n",
    ")\n",
    "ml_specialist_agent.prompt_templates[\"system_prompt\"] = load_prompt_from_file(\"ml_system_prompt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_manager_agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    additional_authorized_imports=['numpy', 'pandas', 'sklearn.metrics, seaborn, sklearn.model_selection, sklearn.preprocessing, sklearn.linear_model'],\n",
    "    name=\"project_manager_agent\",\n",
    "    description=\"Manages data science projects for churn prediction. Breaks down tasks, delegates preprocessing and model training/evaluation to ml_specialist_agent, coordinates their work, synthesizes results, and provides the final ROC-AUC score.\",\n",
    "    managed_agents=[ml_specialist_agent]\n",
    ")\n",
    "\n",
    "\n",
    "project_manager_agent.prompt_templates[\"system_prompt\"] = load_prompt_from_file(\"pm_system_prompt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# task = '''You've been given the files:  \n",
    "# - user_churn/train.csv: training data  \n",
    "# - user_churn/test.csv: data for testing  \n",
    "\n",
    "# Train a Logistic Regression model to predict customer churn ('Churn' column).    \n",
    "# Test the model on the test dataset and report the ROC-AUC score.'''  \n",
    "\n",
    "task = '''Your task is to train a machine learning model and measure the metric on a test set (regression task).\n",
    "You are given 'flat_price/train_flat.csv' (training data) and 'flat_price/test_flat.csv' (testing data).\n",
    "\n",
    "You can train any models from libraries and frameworks that are given to you.\n",
    "You need to predict the target variable 'price'.\n",
    "After training, evaluate the quality on a test set.\n",
    "Evaluate the trained model on the test dataset using the RMSE metric.\n",
    "As a final answer, give: \n",
    "1. The value of the metric \n",
    "2. A description of how the data was processed and the model was trained.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "result = project_manager_agent.run(\n",
    "    task,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
